{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b926a70-b72d-46aa-a8a7-1cb86f87bb83",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Important Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e03f4-030a-4a7c-a1fc-a1fe49b0b59e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## hpo.py and train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b6a0f8-a8cd-468d-a8b9-dd213c88fdbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hpo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hpo.py\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# train function\n",
    "def train(epochs, model, trainloader, optimizer, criterion, device):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data, target in trainloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f\"Epoch {i}: Train loss: {train_loss:.3f}\")\n",
    "\n",
    "# test function\n",
    "def test(model, testloader):\n",
    "    model.to(\"cpu\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)} ({100.0 * correct / len(testloader.dataset):.0f}%)\")\n",
    "\n",
    "# model class\n",
    "class Net(nn.ModuleDict):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(p=.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "         # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flatten image input\n",
    "        x = torch.flatten(x, 1)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "# data loader\n",
    "def dataloaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28,28)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    trainset = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(\"data\", train=False, transform=transform)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size)\n",
    "    \n",
    "    return trainloader, testloader\n",
    "\n",
    "# save model\n",
    "def save(model, model_dir):\n",
    "    path = os.path.join(model_dir, \"model.pth\")\n",
    "    torch.save(model.cpu().state_dict(), path)\n",
    "\n",
    "# main function\n",
    "def main(args):\n",
    "    # setup device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"DEVICE: {device}\")\n",
    "    \n",
    "    # initialize model\n",
    "    logger.info(\"INITIALIZE MODEL\")\n",
    "    model = Net()\n",
    "    model.to(device)\n",
    "    \n",
    "    logger.info(\"CREATING DATA LOADERS\")\n",
    "    trainloader, testloader = dataloaders(args.batch_size)\n",
    "    \n",
    "    logger.info(\"INITIALIZE OPTIMIZER AND CRITERION\")\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    \n",
    "    logger.info(\"BEGIN TRAINING\")\n",
    "    train(args.epochs, model, trainloader, optimizer, criterion, device)\n",
    "    \n",
    "    logger.info(\"BEGIN TESTING\")\n",
    "    test(model, testloader)\n",
    "    \n",
    "    logger.info(\"SAVE MODEL WEIGHTS\")\n",
    "    save(model, args.model_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch MNIST HPO\")\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\", type=int, default=32, metavar=\"N\", help=\"input batch size for both training and testing (default:32)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\", type=int, default=10, metavar=\"N\", help=\"number of epochs to train (default:10)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\", type=float, default=1.0, metavar=\"N\", help=\"learning rate (default: 1.0)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--momentum\", type=float, default=0.9, metavar=\"N\", help=\"momentum for SDG optimizer (default: 0.9)\",\n",
    "    )\n",
    "    # Container environment\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    \n",
    "    # Parse\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ac2be-3c5a-4c87-b4d1-f4de355bd451",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## inference.py\n",
    "\n",
    "Basic method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a553623-128c-49c2-9780-b699bce97c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "class Net(nn.ModuleDict):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(p=.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "         # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flatten image input\n",
    "        x = torch.flatten(x, 1)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# TODO: Add model_fn\n",
    "def model_fn(model_dir):\n",
    "    logger.info(f\"MODEL DIR: {model_dir}\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Net()\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model.to(device).eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96a74f-365a-4e25-a051-697985290ba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## inference_v2.py\n",
    "\n",
    "This one contains all the functions for querying an endpoint from a Lambda Function.\n",
    "\n",
    "Resource: https://sagemaker-examples.readthedocs.io/en/latest/frameworks/pytorch/get_started_mnist_deploy.html\n",
    "\n",
    "Sample Request: {\"image_uri\": \"https://conx.readthedocs.io/en/latest/_images/MNIST_6_0.png\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32ea06e-a234-4f82-bafd-774b5b4eb432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference_v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_v2.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Net(nn.ModuleDict):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(p=.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "         # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flatten image input\n",
    "        x = torch.flatten(x, 1)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# TODO: Add model_fn\n",
    "def model_fn(model_dir):\n",
    "    model = Net()\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    assert request_content_type=='application/json'\n",
    "    # expects a URI\n",
    "    uri = json.loads(request_body)[\"image_uri\"]\n",
    "    logger.info(f\"URI: {uri}\")\n",
    "    data = Image.open(requests.get(uri, stream=True).raw).convert('L')\n",
    "    logger.info(f\"DATA: {data}\")\n",
    "    # preprocess image\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    data = transform(data).unsqueeze(0).to(device)\n",
    "    logger.info(f\"PREPROCESSED DATA: {data}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def predict_fn(input_object, model):\n",
    "    logger.info(f\"PREPROCESSED INPUT DATA: {input_object}\")\n",
    "    with torch.no_grad():\n",
    "        logger.info(f\"MAKE PREDICTIONS\")\n",
    "        prediction = model(input_object)\n",
    "    logger.info(f\"PREDICTIONS: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def output_fn(predictions, content_type):\n",
    "    logger.info(f\"OUTPUT FORMATTER\")\n",
    "    assert content_type == 'application/json'\n",
    "    res = np.argmax(predictions, 1).cpu().numpy().tolist()\n",
    "    return json.dumps(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195f33a-a88d-4aae-9fa1-e447c0e331bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## lambda_function.py\n",
    "\n",
    "Lambda function using Boto3 for querying the endpoint using inference_v2.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f016268e-3634-4257-8f11-ae33d70c9973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_function.py\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "runtime = boto3.Session().client('sagemaker-runtime')\n",
    "endpoint_name = 'mnist-endpoint'\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print('Context:::', context)\n",
    "    print('EventType::', type(event))\n",
    "    \n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName = endpoint_name,\n",
    "        ContentType = 'application/json',\n",
    "        Accept = 'application/json',\n",
    "        Body = json.dumps(event)\n",
    "    )\n",
    "    \n",
    "    result = response['Body'].read().decode('utf-8')\n",
    "    result = json.loads(result)\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'headers' : { 'Content-Type' : 'text/plain', 'Access-Control-Allow-Origin' : '*' },\n",
    "        'type-result':str(type(result)),\n",
    "        'Content-Type-In':str(context),\n",
    "        'body' : json.dumps(result),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ac13e-3f16-40ff-b1c8-d9b102499098",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17cbb65c-5562-4ea6-969d-aa39c37a18ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96907a8-c7be-46c1-af14-66655a82e1ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sagemaker Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54ef9230-efa3-441d-b7e5-7246d5befdbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a2206c-267f-40ec-8c65-3a1f64f12dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-250672895001\n",
      "RoleArn: arn:aws:iam::250672895001:role/service-role/AmazonSageMaker-ExecutionRole-20230209T083631\n"
     ]
    }
   ],
   "source": [
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b0c83-783e-43a8-8657-ec5b8154d55d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba8a9117-9ce6-4d0d-a0c1-f69fdb752c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.01, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([32, 64]),\n",
    "    \"epochs\": IntegerParameter(5, 10),\n",
    "    \"momentum\": ContinuousParameter(0.5, 0.9), # Adding this since SDG is the optimization function chosen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7434fd61-eaca-4119-95a4-90266ab86647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \"Regex\": \"Test Loss: ([+-]?[0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f07cfc-ff7c-4384-b744-ea442095a826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=role,\n",
    "    py_version=\"py36\",\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "# Tuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    "    early_stopping_type=\"Auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f39642df-ff1f-407a-a40a-324af6220a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d75783a-a1f9-4643-9431-13227882045c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-02-10 07:15:20 Starting - Found matching resource for reuse\n",
      "2023-02-10 07:15:20 Downloading - Downloading input data\n",
      "2023-02-10 07:15:20 Training - Training image download completed. Training in progress.\n",
      "2023-02-10 07:15:20 Uploading - Uploading generated training model\n",
      "2023-02-10 07:15:20 Completed - Resource retained for reuse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"average test loss\"',\n",
       " 'batch-size': '\"64\"',\n",
       " 'epochs': '10',\n",
       " 'lr': '0.01917874652567949',\n",
       " 'momentum': '0.6984716955702364',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch-training-2023-02-10-06-50-26-699\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-250672895001/pytorch-training-2023-02-10-06-50-26-699/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best estimators with the best Hyperparameters\n",
    "best_estimator = tuner.best_estimator()\n",
    "\n",
    "# Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ccb5b-aa01-43b3-bd52-38e3bbaac3bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9f58c72-1297-4580-9290-abcb89aeb440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_hyperparameters = {\n",
    "    \"batch-size\": int(best_estimator.hyperparameters()[\"batch-size\"].replace('\"', \"\")),\n",
    "    \"epochs\": best_estimator.hyperparameters()[\"epochs\"],\n",
    "    \"lr\": best_estimator.hyperparameters()[\"lr\"],\n",
    "    \"momentum\": best_estimator.hyperparameters()[\"momentum\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfae7375-3094-4743-9333-7bcf8db70c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    framework_version=\"1.6\", # using 1.6 as it has support for smdebug lib , https://github.com/awslabs/sagemaker-debugger#debugger-supported-frameworks\n",
    "    py_version=\"py36\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    hyperparameters=best_hyperparameters,\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f46d1808-d443-469f-9e9d-93925216fc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-10 07:27:45 Starting - Starting the training job...\n",
      "2023-02-10 07:28:00 Starting - Preparing the instances for trainingProfilerReport-1676014064: InProgress\n",
      "......\n",
      "2023-02-10 07:29:11 Downloading - Downloading input data...\n",
      "2023-02-10 07:29:41 Training - Downloading the training image......\n",
      "2023-02-10 07:30:31 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:26,941 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:26,944 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:26,954 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:26,957 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:27,122 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:27,135 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:27,147 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-10 07:30:27,157 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": \"10\",\n",
      "        \"lr\": \"0.01917874652567949\",\n",
      "        \"momentum\": \"0.6984716955702364\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-02-10-07-27-44-685\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-250672895001/pytorch-training-2023-02-10-07-27-44-685/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":\"10\",\"lr\":\"0.01917874652567949\",\"momentum\":\"0.6984716955702364\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-250672895001/pytorch-training-2023-02-10-07-27-44-685/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":\"10\",\"lr\":\"0.01917874652567949\",\"momentum\":\"0.6984716955702364\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-02-10-07-27-44-685\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-250672895001/pytorch-training-2023-02-10-07-27-44-685/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"10\",\"--lr\",\"0.01917874652567949\",\"--momentum\",\"0.6984716955702364\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01917874652567949\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.6984716955702364\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch-size 64 --epochs 10 --lr 0.01917874652567949 --momentum 0.6984716955702364\u001b[0m\n",
      "\u001b[34mDEVICE: cpu\u001b[0m\n",
      "\u001b[34mINITIALIZE MODEL\u001b[0m\n",
      "\u001b[34mCREATING DATA LOADERS\u001b[0m\n",
      "\u001b[34mDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\u001b[0m\n",
      "\u001b[34mDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\u001b[0m\n",
      "\u001b[34mDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\u001b[0m\n",
      "\u001b[34mDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\u001b[0m\n",
      "\u001b[34mProcessing...\u001b[0m\n",
      "\u001b[34mDone!\u001b[0m\n",
      "\u001b[34mINITIALIZE OPTIMIZER AND CRITERION\u001b[0m\n",
      "\u001b[34mBEGIN TRAINING\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.584 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.778 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.779 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.779 algo-1:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.780 algo-1:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.780 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.790 algo-1:26 INFO hook.py:584] name:conv1.weight count_params:288\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.790 algo-1:26 INFO hook.py:584] name:conv1.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.790 algo-1:26 INFO hook.py:584] name:conv2.weight count_params:18432\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.790 algo-1:26 INFO hook.py:584] name:conv2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.790 algo-1:26 INFO hook.py:584] name:fc1.weight count_params:1605632\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.790 algo-1:26 INFO hook.py:584] name:fc1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.790 algo-1:26 INFO hook.py:584] name:fc2.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.791 algo-1:26 INFO hook.py:584] name:fc2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.791 algo-1:26 INFO hook.py:584] name:fc3.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.791 algo-1:26 INFO hook.py:584] name:fc3.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.791 algo-1:26 INFO hook.py:584] name:fc4.weight count_params:640\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.791 algo-1:26 INFO hook.py:584] name:fc4.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.791 algo-1:26 INFO hook.py:586] Total Trainable Params: 1773386\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.791 algo-1:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-02-10 07:30:28.794 algo-1:26 INFO hook.py:476] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34mEpoch 0: Train loss: 1055.843\u001b[0m\n",
      "\u001b[34mEpoch 1: Train loss: 202.395\u001b[0m\n",
      "\u001b[34mEpoch 2: Train loss: 130.750\u001b[0m\n",
      "\u001b[34mEpoch 3: Train loss: 98.436\u001b[0m\n",
      "\u001b[34mEpoch 4: Train loss: 83.372\u001b[0m\n",
      "\u001b[34mEpoch 5: Train loss: 73.502\u001b[0m\n",
      "\u001b[34mEpoch 6: Train loss: 61.277\u001b[0m\n",
      "\u001b[34mEpoch 7: Train loss: 53.602\u001b[0m\n",
      "\u001b[34mEpoch 8: Train loss: 51.283\u001b[0m\n",
      "\u001b[34mEpoch 9: Train loss: 47.371\u001b[0m\n",
      "\u001b[34mBEGIN TESTING\u001b[0m\n",
      "\u001b[34mTest Loss: 0.0282, Accuracy: 9916/10000 (99%)\u001b[0m\n",
      "\u001b[34mSAVE MODEL WEIGHTS\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#033[A#033[A#033[A/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /codebuild/output/src450209981/src/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\u001b[0m\n",
      "\u001b[34m#01532768it [00:00, 132062.17it/s]\u001b[0m\n",
      "\u001b[34m#0151654784it [00:00, 7131718.76it/s]\u001b[0m\n",
      "\u001b[34m#0158192it [00:00, 53740.50it/s]\u001b[0m\n",
      "\u001b[34m#0159920512it [00:00, 13446235.01it/s]\u001b[0m\n",
      "\u001b[34mINFO:__main__:BEGIN TESTING\u001b[0m\n",
      "\u001b[34mINFO:__main__:SAVE MODEL WEIGHTS\u001b[0m\n",
      "\u001b[34m2023-02-10 07:41:03,388 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-02-10 07:41:21 Uploading - Uploading generated training model\n",
      "2023-02-10 07:41:21 Completed - Training job completed\n",
      "Training seconds: 734\n",
      "Billable seconds: 734\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4faf4c-da67-4999-a97e-4fe46b48ef07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac87b449-03ec-4078-b3ee-6f275208b04a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: s3://sagemaker-us-east-1-250672895001/pytorch-training-2023-02-10-07-27-44-685/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data = estimator.output_path + estimator.latest_training_job.job_name + \"/output/model.tar.gz\"\n",
    "print(f\"Model: {model_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2727a92a-39ec-4fd0-878b-db08fd5cd309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "# TODO: Add Model Loader\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    ")\n",
    "\n",
    "# TODO: Deploy\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "646421af-a9bd-48d0-9672-866fb404cba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "# Method 2\n",
    "model_v2 = PyTorchModel(\n",
    "    entry_point=\"inference_v2.py\",\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    ")\n",
    "\n",
    "# TODO: Deploy\n",
    "predictor_v2 = model_v2.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\", endpoint_name=\"mnist-endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9ae92-a591-43d3-b40f-e954c98435a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "Utilizes endpoint from inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2e226e4-5601-4503-a67a-9ed4a5d0bf0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.14.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.9.24)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# installing these as they'll be needed for inference\n",
    "!pip3 install torch torchvision --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68f71efd-ebac-4ed7-bdc0-856c91cf443b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run an prediction on the endpoint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "06f6e1b8-846e-48ce-93bf-ed9e4f8e3831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Predict function that takes in an image, preprocesses it, and uses the endpoint for prediction\n",
    "def predict(image_path):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    preprocessed_image = transform(image).unsqueeze(0)\n",
    "    preprocessed_image = preprocessed_image.to(\"cpu\")\n",
    "\n",
    "    response = predictor.predict(preprocessed_image)\n",
    "    pred = np.argmax(response, 1)\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.show()\n",
    "    print(f\"Actual: {image_path[:2]}, Prediction: {pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60c8c99e-49e7-4f64-b56f-636a8127cde4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 0., Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test prediction\n",
    "predict(\"0.webp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a90fd8-fb57-406c-a19f-2073f6fda67b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03c73ab0-afb7-473d-9254-77834d3e726a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Delete endpoint\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5187d390-f1ee-46c9-a669-fa48c764913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_v2.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cb20d-7bf6-43d9-ae6f-2cbf065b02b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "55e1df681a2c9dd5350b2fe2c27ebb71b6c3a19121d9bdbcc8e97e0cb57b972a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
